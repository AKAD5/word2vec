\chapter{在贫困生预测中的应用}
SVM算法的理论基础是凸二次规划问题的对偶问题的求解，通过引入核函数，实现高维空间非线性映射向量的内积计算，从而完成对非线性问题的求解。
算法的目标是找到特征空间上的最优超平面，结果是找到支持向量（距离超平面最近的点），在分类决策中，起重要作用的是这些支持向量。\\
具有以下优点：
\begin{itemize}
    \item 理论完善，有一套几乎完美的理论可以解释其原理。
    \item 少数支持向量决定了最终结果,具有较好的“鲁棒”性。
    \item 泛化能力强
\end{itemize}
缺点：
\begin{itemize}
    \item 大样本数据量会消耗大量的内存和运算时间。
    主要改进有有J.Platt的SMO算法、T.Joachims的SVM、C.J.C.Burges等的PCGC、张学工的CSVM以及O.L.Mangasarian等的SOR算法
    \item 经典的支持向量机算法只给出了二类分类的算法,多分类问题需通过多个二类支持向量机的组合来解决
\end{itemize}

在贫困生预测中，我们的输入空间是学生的各项消费指标，输出是学生是否贫困的类标记，这里属于一个二分类问题，可以非常方便的应用SVM算法。另一方面，我们不仅想知道学生是否贫困，还需要知道学生是贫困生的概率，通过概率来计算贫困指数。在SVM算法的描述中，我们并未涉及到概率，模型是无法直接输出概率的，解决办法有两个。

1. 利用决策函数
$$ f(x) = sgn(\sum_{i=1}^N \alpha_i^* y_i K(x, x_i) +b^*) $$
符号函数里面的部分是样本点x到决策边界的函数距离，这个距离可以用来衡量决策的确信度，作为概率的一种反映用于贫困指数的计算中。

2. Platt标度\\
这是一种是一种参数化方法,使用LR模型（sigmoid函数)对模型的输出值进行拟合，将模型的原始输出值映射为概率值，区间（0，1）。假设f(x)为模型的输出值，那么：
$$
    P(y=1|f) = \frac{1}{1+exp(A*f+B)}
$$
A，B通过训练集使用极大似然法解得。
