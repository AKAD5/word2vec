\chapter{基本理论}
\section{支持向量，间隔}
设给定一训练样本集$D={(x_1,y_1), (x_2,y_2), ..., (x_m,y_m)}$，$y_i \in {-1,+1}$，分类学习最基本的想法是基于训练集D在样本空间中找到一个超平面，将不同的样本分开。
在样本空间中，划分超平面可通过如下线性方程描述：
$$ w^Tx+b=0 $$
其中：$w=(w_1,w_2,w_3, ..., w_d)$ ,是超平面的法向量，决定其方向；b是偏移项，决定向量与原点之间的距离，于是超平面可记为$(w,b)$。
样本空间中任一点x到超平面$(w,b)$的距离计算公式如下：
$$ r = \frac{|w^Tx+b}{|w|} $$
假设超平面$(w,b)$能将样本正确分类，对于$(x_i,y_i) \in D$，下述公式成立：
$$
\begin{cases}
    w^Tx+b \geqslant +1,& y_i=+1; \\
    w^Tx+b \leqslant -1,& y_i=-1;
\end{cases}
$$
距离超平面最近的几个样本使得上式等号成立，这些样本被称为支持向量，两个异类支持向量的和定义为间隔：
$$ \gamma = \frac{2}{|w|} $$
找到按照上式约束的参数w，b，使得$\gamma$最大，此时的超平面具有最大间隔，即：
$$
\begin{matrix}
    \underset{w,b}{max} \frac{2}{|w|} \\
    s.t. \quad y_i(w^Tx_i+b) \geqslant 1, i=1,2,...,m
\end{matrix}
$$
可见，最大化间隔，等于最大化$|w|^{-1}$，等价于最小化$|w|^2$，于是：
$$
\begin{matrix}
    \underset{w,b}{max}{\frac{1}{2}|w|^2} \\
    s.t. \quad y_i(w^Tx_i+b) \geqslant 1, i=1,2,...,m
\end{matrix}
$$

\section{对偶问题}
